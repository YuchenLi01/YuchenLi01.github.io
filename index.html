<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yuchen Li</title>

  <meta name="author" content="me">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cmu_scs_dragon.ico">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:2.5%">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:0%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yuchen Li</name>
              </p>
              <p>I am a PhD student at the <a href="https://www.ml.cmu.edu/">Machine Learning Department</a> in <a href="https://www.cmu.edu/">Carnegie Mellon University</a>.
                 I am fortunate to be advised by Professor <a href="https://www.andrew.cmu.edu/user/aristesk/">Andrej Risteski</a>.
              </p>
              <p>
                Previously, I spent four wonderful years at the <a href="https://illinois.edu/">University of Illinois at Urbana-Champaign</a>,
                completing my bachelor's degree in Statistics & Computer Science, as well as Mathematics.
                I am grateful for the mentorship of Professor <a href="http://hanj.cs.illinois.edu/">Jiawei Han</a>, Professor <a href="https://faculty.math.illinois.edu/~hildebr/">AJ Hildebrand</a>, and Professor <a href="http://pramodv.ece.illinois.edu/">Pramod Viswanath</a>.
              </p>
              <p>
                In the industry, I spent some exciting time at <a href="https://www.quora.com/">Quora</a>
                and <a href="https://about.facebook.com/">Facebook</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yuchenl4@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/Yuchen-Li-cv.pdf">CV</a> &nbsp/&nbsp
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://www.linkedin.com/in/yuchenli01/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=2Uu9K30AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/_Yuchen_Li_">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/YuchenLi01/">GitHub</a>
              </p>
            </td>
            <td style="padding:0%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/adv28.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>
        <br><br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0%;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I study machine learning, natural language processing, and data mining.
                My long-term goals include improving mathematical understanding of empirical phenomena, and developing principled approaches to modern deep learning applications.
              </p>
            </td>
          </tr>
        </tbody></table>
        <br><br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0%;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                In the following list, the asterisk symbol (*) in the author list means equal contribution or alphabetical order.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/pcfg_context.png" alt="pcfg_context" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2106.01580">
                <papertitle>The Limitations of Limited Context for Constituency Parsing</papertitle>
              </a>
              <br>
                <strong>Yuchen Li*</strong>,
                <a href="https://www.andrew.cmu.edu/user/aristesk/">Andrej Risteski*</a>
              <br>
              <em>Association for Computational Linguistics (ACL)</em>, 2021
              <br>
              <a href="data/li2021limitations.bib">bibtex</a> /
              <a href="data/li2021limitations_slides.pdf">slides</a> /
              <a href="https://twitter.com/_yuchen_li_/status/1402413507115692035?s=21">My Twitter post</a> /
              <a href="https://twitter.com/risteski_a/status/1402110089801179139?s=21">Andrej's Twitter post</a>
              <p>We prove that, if the context for the parsing decision at each word is <em>unbounded</em> & <em>bidirectional</em>,
                then the parsing model has full representational power.
              </p>
              <p>On the other hand, even if the context is bounded in one direction (which is the case for various leading approaches to constituency parsing),
                the parsing power is quite limited for hard grammars.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/complexity.png" alt="complexity" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1804.00221">
                <papertitle>Complexity of Leading Digit Sequences</papertitle>
              </a>
              <br>
                <a href="https://www.linkedin.com/in/xinwei-he-586512134/">Xinwei He*</a>,
                <a href="https://faculty.math.illinois.edu/~hildebr/">AJ Hildebrand*</a>,
                <strong>Yuchen Li*</strong>,
                <a href="https://yzhan238.github.io/">Yunyi Zhang*</a>
              <br>
              <em>Journal of Discrete Mathematics & Theoretical Computer Science (DMTCS)</em>, vol. 22 no. 1, Automata, Logic and Semantics 2020 &nbsp
              <br>
              <a href="data/he2020complexity.bib">bibtex</a> /
              <a href="data/Complexity_Poster_JMM_2018.pdf">poster</a>
              <p>Consider the sequence of leading digits of 2^n: 1, 2, 4, 8, 1, 3, 6, ......
                What is the <em>complexity</em> of such sequences?
                They are neither <em>periodic</em> nor <em>random</em>.
                How to quantify and distinguish the middle ground?
              </p>
              <p>We prove that, the <em>block complexity is linear</em> for the sequence of leading digits of a^n in base b (except for some special cases).
                In fact, we give explicit formula for the linear coefficients in terms of a and b.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/HyperMine.png" alt="HyperMine" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1909.01584">
                <papertitle>Discovering Hypernymy in Text-Rich Heterogeneous Information Network by Exploiting Context Granularity</papertitle>
              </a>
              <br>
                <a href="https://yu-shi-homepage.github.io/">Yu Shi*</a>,
                <a href="http://mickeystroller.github.io/">Jiaming Shen*</a>,
                <strong>Yuchen Li</strong>,
                <a href="https://www.linkedin.com/in/naijing-zhang/">Naijing Zhang</a>,
                <a href="https://www.linkedin.com/in/xinwei-he-586512134/">Xinwei He</a>,
                <a href="https://www.linkedin.com/in/samuel-lou-70540490/">Zhengzhi Lou</a>,
                <a href="https://gentlezhu.github.io/">Qi Zhu</a>,
                <a href="https://www.linkedin.com/in/matthewhhwalker/">Matthew Walker</a>,
                <a href="http://infolab.stanford.edu/~mykim/">Myunghwan Kim</a>,
                <a href="http://hanj.cs.illinois.edu/">Jiawei Han</a>
              <br>
              <em>Conference on Information and Knowledge Management (CIKM)</em>, 2019
              <br>
              <a href="data/shi2019discovering.bib">bibtex</a>
              <p>This work discovers hypernym-hyponym ("is-a" relation) pairs by an innovative combination of information from natural language and graph structure.
                Our system outperforms existing methods that utilize signals from text, graph, or both.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/spell_correction.png" alt="spell_correction" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1901.07688">
                <papertitle>Context-Sensitive Malicious Spelling Error Correction</papertitle>
              </a>
              <br>
                <a href="https://hongyugong.github.io/">Hongyu Gong</a>,
                <strong>Yuchen Li</strong>,
                <a href="https://publish.illinois.edu/sumapbhat/">Suma Bhat</a>,
                <a href="http://pramodv.ece.illinois.edu/">Pramod Viswanath</a>
              <br>
              <em>The Web Conference (WWW)</em>, 2019
              <br>
              <a href="data/gong2019context.bib">bibtex</a>
              <p>Given a misspelled word, our algorithm generates candidates based on the surface form,
                represents the context as a linear space, and
                selects the candidate whose embedding is closest to the context subspace.
                The spelling correction accuracy is better than the state-of-the-art methods, improving the performance in downstream applications.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/hin_motif.png" alt="hin_motif" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="middle">
              <a href="http://www.mlgworkshop.org/2018/papers/MLG2018_paper_46.pdf">
                <papertitle>Temporal Motifs in Heterogeneous Information Networks</papertitle>
              </a>
              <br>
                <strong>Yuchen Li*</strong>,
                <a href="https://www.linkedin.com/in/samuel-lou-70540490/">Zhengzhi Lou*</a>,
                <a href="https://yu-shi-homepage.github.io/">Yu Shi</a>,
                <a href="http://hanj.cs.illinois.edu/">Jiawei Han</a>
              <br>
              <em>Workshop on Mining and Learning with Graphs (MLG), in conjunction with KDD</em>, 2018
              <br>
              <a href="data/li2018temporal.bib">bibtex</a>
              <p>This work shows the effectiveness of temporal motifs (frequent substructures)
                in quantifying the relationship between nodes in heterogeneous information networks,
                and proposes efficient algorithms for counting a family of useful motifs.
              </p>
            </td>
          </tr>

        </tbody></table>
        <br><br>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0%;width:100%;vertical-align:middle">
              <heading>Talks</heading>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:0%;width:35%;vertical-align:middle">
              <img src="images/pcfg_context.png" alt="pcfg_context" style="width:100%;max-width:100%">
            </td>
            <td width="75%" valign="center">
              <papertitle>The Limitations of Limited Context for Constituency Parsing</papertitle>
              <br>
              <a href="data/li2021limitations_slides.pdf">slides</a>
              <br><br>
              <a href="https://2021.aclweb.org/">Association for Computational Linguistics (ACL) Conference</a>
              , Virtual, August 2021
              <br>
              <a href="https://www.neclab.eu/">NEC Laboratories Europe</a>
              , Virtual, July 2021
              <br>
              <a href="https://acmilab.org/">Approximately Correct Machine Intelligence (ACMI) Lab, CMU</a>
              , Virtual, June 2021
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0%">
              <br>
              <p style="text-align:right;font-size:small;">
                Template of this page: credit to: <a href="https://github.com/jonbarron/jonbarron_website">link</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <br><br>

      </td>
    </tr>
  </tbody></table>
</body>

</html>
